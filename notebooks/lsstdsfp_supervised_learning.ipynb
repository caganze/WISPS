{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splat\n",
    "import wisps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wisps import Annotator as an\n",
    "from wisps import datasets\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Training Set\n",
    "\n",
    "My training set has wisps stuff and trash i.e things that I know are not bds\n",
    "\n",
    "But not all of them, I'll just pick 4000 random objects to keep the proportion reasonable? It's a way of scaling my data idk\n",
    "if this is the right way to go about it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=datasets['traing_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['x']=train_df.spex_chi/train_df.line_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['CH_4/H-Cont', 'CH_4/H_2O-1', 'CH_4/H_2O-2', 'CH_4/J-Cont',\n",
    "       'H-cont/H_2O-1', 'H-cont/H_2O-2', 'H-cont/J-Cont', 'H_2O-1/J-Cont',\n",
    "       'H_2O-2/H_2O-1', 'H_2O-2/J-Cont',  'spex_chi', 'snr2', 'snr1',\n",
    "       'line_chi', 'x', 'f_test']\n",
    "label='label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Prediction Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=wisps.Annotator.reformat_table(pd.read_hdf(wisps.COMBINED_PHOTO_SPECTRO_FILE, key='stars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spt']=data.spt.apply(splat.typeToNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##only look at things with snr >3.0\n",
    "#data=data[(data.snr1>3.0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=wisps.Annotator.reformat_table(data[features]).applymap(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply logarithms to features that might be problematic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prblm_feats=['line_chi', 'spex_chi', 'H_2O-2/J-Cont', 'H-cont/J-Cont', 'H_2O-1/J-Cont', 'H-cont/H_2O-1', 'snr2', 'snr1', 'x']\n",
    "pred_df[prblm_feats]=pred_df[prblm_feats].applymap(np.log10).replace(np.inf, np.nan).replace(-np.inf, np.nan).replace(np.nan, -999999.9)\n",
    "train_df[prblm_feats]=train_df[prblm_feats].applymap(np.float).applymap(np.log10).replace(np.inf, np.nan).replace(-np.inf, np.nan).replace(np.nan, -999999.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename the class only make 2 classes: brown dwarf and not brown dwarf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_binary(labl):\n",
    "    ##only two labels\n",
    "    if labl >0.:\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label']=train_df['label'].apply(make_label_binary)\n",
    "#pred_df['label']=pred_df['label'].apply(make_label_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data to avoid weird stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#train_set=train_df[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[features].values, train_df[label].values, test_size=0.5,  random_state=123456) ###grammar  \n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#scale the data set to predict for \n",
    "pred_set=scaler.transform(pred_df[features].replace(-np.inf, np.nan).replace(np.inf, np.nan).replace(np.nan,  -999999.9).values)\n",
    "\n",
    "#cleanup\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "def train_model(nestimators=100, random_state=123456):\n",
    "    \"\"\"\n",
    "    trains the model given different parameters\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=nestimators, oob_score=True, random_state=random_state)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    return rf\n",
    "\n",
    "rf=train_model(nestimators=10000, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(X_test).any(), np.isinf(X_test).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import seaborn as sns\n",
    "pred_labels = rf.predict(X_test)\n",
    "model_accuracy = accuracy_score(y_test, pred_labels)\n",
    "\n",
    "print ('accuracy score {}'.format(model_accuracy))\n",
    "classes=['non-UCD', 'UCD']\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred_labels), \n",
    "                  columns=classes, index=classes)\n",
    "\n",
    "sns.heatmap(cm, annot=True, cmap=wisps.MYCOLORMAP)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(wisps.OUTPUT_FIGURES+'/confusion_matrix.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#def plot_histogram(index):\n",
    "#    fig, ax=plt.subplots()\n",
    "#    #plt.xscale('log')\n",
    "#    plt.yscale('log')\n",
    "#    plt.hist(pred_set[:, index], bins=50)\n",
    "    \n",
    "#for index in np.arange(0, 13): plot_histogram(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=rf.predict(pred_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(labels==1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[(labels==1)& (data.f_test<0.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands=pd.read_hdf(wisps.OUTPUT_FILES+'/true_spectra_cands.hdf', key='with_indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['grism_id']=data.grism_id.apply(lambda x: x.lower().stip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands['grism_id']=cands.grism_id.apply(lambda x: x.lower().stip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_p=len(data[(data.grism_id.isin(cands.grism_id.values)) & (labels==1)])\n",
    "tru_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len((data[(labels==1)])), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(data[labels==1])-tru_p)/len(data[labels==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[(labels==1)]).to_pickle(wisps.LIBRARIES+'/labelled_by_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(data[(labels==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the random forest\n",
    "output_file=wisps.OUTPUT_FILES+'/random_forest_classifier.pkl'\n",
    "with open(output_file, 'wb') as file:\n",
    "    pickle.dump(rf,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the random forest\n",
    "output_file2=wisps.OUTPUT_FILES+'/min_max_scaler.pkl'\n",
    "with open(output_file2, 'wb') as file:\n",
    "    pickle.dump(scaler,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
