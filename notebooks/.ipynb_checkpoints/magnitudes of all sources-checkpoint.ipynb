{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 89 sources from /Users/caganze/research/splat//resources/Spectra/Public/MAGE/ to spectral database\n",
      "Adding 2404 sources from /Users/caganze/research/splat//resources/Spectra/Public/SPEX-PRISM/ to spectral database\n",
      "Adding 145 sources from /Users/caganze/research/splat//resources/Spectra/Public/LRIS-RED/ to spectral database\n",
      "\n",
      "Warning: spectrum object has a flux vector of zero length - maybe empty?\n",
      "\n",
      "Warning: normalize is attempting to divide by nan; ignoring\n",
      "\n",
      "Warning: spectrum object has a flux vector of zero length - maybe empty?\n",
      "\n",
      "Warning: normalize is attempting to divide by nan; ignoring\n",
      "\n",
      "Warning: spectrum object has a flux vector of zero length - maybe empty?\n",
      "\n",
      "Warning: normalize is attempting to divide by nan; ignoring\n",
      "\n",
      "Warning: spectrum object has a flux vector of zero length - maybe empty?\n",
      "\n",
      "Warning: normalize is attempting to divide by nan; ignoring\n",
      "\n",
      "Warning: spectrum object has a flux vector of zero length - maybe empty?\n",
      "\n",
      "Warning: normalize is attempting to divide by nan; ignoring\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wisps\n",
    "import wisps.simulations as wispsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from astropy.coordinates import SkyCoord\n",
    "from multiprocessing import Pool\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.integrate as integrate\n",
    "import bisect\n",
    "import numba\n",
    "\n",
    "#contants\n",
    "PNTS=[]\n",
    "DISTANCE_LIMITS=[]\n",
    "SPGRID=n.array([17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "       34, 35, 36, 37, 38, 39, 40, 41])\n",
    "Rsun=8300.\n",
    "Zsun=27.\n",
    "HS=[150,200,250, 300,350,400, 450, 500]\n",
    "INTERPOLATED_CDFS=[]\n",
    "#redefine magnitude limits by taking into account the scatter for each pointing \n",
    "#use these to compute volumes\n",
    "\n",
    "#REDEFINED_MAG_LIMITS={'F110':    23.054573, 'F140':    23.822972, 'F160' :   23.367867}\n",
    "\n",
    "#-------------------------------------------\n",
    "def random_draw(xvals, cdfvals, nsample=10):\n",
    "    \"\"\"\n",
    "    randomly drawing from a discrete distribution\n",
    "    \"\"\"\n",
    "    @numba.vectorize(\"int32(float64)\")\n",
    "    def invert_cdf(i):\n",
    "        return bisect.bisect(cdfvals, i)-1\n",
    "    x=np.random.rand(nsample)\n",
    "    idx=invert_cdf(x)\n",
    "    return np.array(xvals)[idx]\n",
    "\n",
    "def density_function(r, z, h=300.):\n",
    "    \n",
    "    \"\"\"\n",
    "    A custom juric density function that only uses numpy arrays for speed\n",
    "    All units are in pc\n",
    "    \"\"\"\n",
    "    l = 2600. # radial length scale of exponential thin disk \n",
    "    zpart=np.exp(-abs(z-Zsun)/h)\n",
    "    rpart=np.exp(-(r-Rsun)/l)\n",
    "    return zpart*rpart\n",
    "\n",
    "\n",
    "def custom_volume(l,b,dmin, dmax, h):\n",
    "    nsamp=1000\n",
    "    ds = np.linspace(dmin,dmax,nsamp)\n",
    "    rd=np.sqrt( (ds * np.cos( b ) )**2 + Rsun * (Rsun - 2 * ds * np.cos( b ) * np.cos( l ) ) )\n",
    "    zd=Zsun+ ds * np.sin( b - np.arctan( Zsun / Rsun) )\n",
    "    rh0=density_function(rd, zd,h=h )\n",
    "    val=integrate.trapz(rh0*(ds**2), x=ds)\n",
    "    return val\n",
    "\n",
    "def interpolated_cdf(pntname, h):\n",
    "    pnt= POINTINGS[pntname]\n",
    "    l, b= pnt.coord.galactic.l.radian, pnt.coord.galactic.b.radian\n",
    "    d=np.concatenate([[0], np.logspace(-1, np.log10(5000), int(1e2))])\n",
    "    cdfvals=np.array([custom_volume(l,b,0, dx, h) for dx in d])\n",
    "    return interp1d(d, cdfvals)\n",
    "\n",
    "def draw_distance_with_cdf(pntname, dmin, dmax, nsample, h):\n",
    "    #draw distances using inversion of the cumulative distribution \n",
    "    d=np.logspace(np.log10(dmin), np.log10(dmax), int(nsample))\n",
    "    cdfvals=(INTERPOLATED_CDFS[h][pntname])(d)\n",
    "    return wisps.random_draw(d, cdfvals/np.nanmax(cdfvals), int(nsample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnts=pd.read_pickle(wisps.OUTPUT_FILES+'/pointings_correctedf110.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lb(pnt):\n",
    "    l, b= pnt.coord.galactic.l.radian, pnt.coord.galactic.b.radian\n",
    "    return pd.Series({'l':l, 'b': b}, index=[pnt.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wispsim.SPGRID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
