{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wisps\n",
    "import splat\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold,RepeatedKFold\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=pd.read_hdf(wisps.COMBINED_PHOTO_SPECTRO_FILE, key='new_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=comb.iloc[(comb[wisps.INDEX_NAMES]).dropna().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=comb.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_pickle(wisps.LIBRARIES+'/training_set.pkl').reset_index(drop=True)\n",
    "                                                                           \n",
    "pred_df=wisps.Annotator.reformat_table(comb).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pred_df.drop_duplicates(subset='grism_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scale(x):\n",
    "    ##put features on a log scale\n",
    "    #replace nans\n",
    "    y=np.log10(x)\n",
    "    if np.isnan(y) or np.isinf(y):\n",
    "        y=np.random.uniform(-99, -98)\n",
    "    return y\n",
    "\n",
    "def create_labels(row):\n",
    "    #use multiclass system\n",
    "    label=0\n",
    "    if row.label ==0.:\n",
    "        label=0\n",
    "    if (row.label==1) & (row.spt <20):\n",
    "        label=1\n",
    "    if (row.label==1) & np.logical_and(row.spt >=20, row.spt<30):\n",
    "        label=2\n",
    "    if (row.label==1) & np.logical_and(row.spt >=30, row.spt<45):\n",
    "        label=3\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_df['grism_id']=pred_df.grism_id.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=wisps.INDEX_NAMES\n",
    "features=np.concatenate([['snr2','snr1', 'snr3', 'snr4', 'f_test', 'line_chi', 'spex_chi'], wisps.INDEX_NAMES])\n",
    "#features=['snr2','snr1', 'snr3', 'snr4', 'f_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pred_df[pred_df.snr2>3.]\n",
    "train_df['spt']=train_df.spt.apply(wisps.make_spt_number)\n",
    "pred_df['spt']=pred_df.spt.apply(wisps.make_spt_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=train_df.apply(create_labels, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[features]=(train_df[features]).applymap(apply_scale)\n",
    "pred_df[features]=(pred_df[features]).applymap(apply_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-100, 100))\n",
    "scaler.fit(train_df[features])\n",
    "X=scaler.transform(train_df[features])\n",
    "y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data set to predict for the prediction set\n",
    "pred_set=scaler.transform(pred_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weigths={0:1., 1:40/10000, 2:1/10000, 3:5/10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.5,  random_state=np.random.randint(1000))\n",
    "    \n",
    "rf = RandomForestClassifier(n_estimators=10000, min_samples_split=2, verbose=True,bootstrap=True, n_jobs=-1, \n",
    "                            class_weight=class_weigths, criterion='entropy',  random_state=np.random.randint(1000), \n",
    "                            warm_start=False)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_labels = rf.predict(X_test)\n",
    "model_accuracy = accuracy_score(y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('accuracy score {}'.format(model_accuracy))\n",
    "classes=['non-UCD', 'M7-L0', 'L', 'T']\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, pred_labels), \n",
    "                  columns=classes, index=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a table a confusion matrix\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(8, 6))\n",
    "\n",
    "matr=(cm/cm.sum()).applymap(lambda x: np.round(x, 2)).values\n",
    "im = ax.imshow(matr, cmap='Blues')\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        text = ax.text(j, i, matr[i, j], ha=\"center\", va=\"center\", color=\"k\", fontsize=18)\n",
    "ax.set_xlim([-0.5, 3.5])\n",
    "ax.set_ylim([3.5, -0.5])\n",
    "plt.tight_layout()\n",
    "plt.savefig(wisps.OUTPUT_FIGURES+'/confusion_matrix.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#cleanup\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'accuracy score {}'.format(model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlabels=rf.predict(pred_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rlabels[rlabels>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands=pd.read_pickle(wisps.OUTPUT_FILES+'/true_spectra_cands.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands['grism_id']=cands.grism_id.apply(lambda x: x.lower())\n",
    "cands['spt']=[x.spectral_type for x in cands.spectra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cands), len( pred_df[pred_df.grism_id.isin(cands.grism_id.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs=wisps.datasets['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands[~ cands.grism_id.isin(pred_df.grism_id.values) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands[~ cands.grism_id.isin(strs.grism_id.values) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands=cands[cands.spt>=17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=(pred_df[(rlabels>0) & pred_df.grism_id.isin(cands.grism_id.values)]).drop_duplicates(subset='grism_id')\n",
    "truep=len(true)\n",
    "ps=len(rlabels[rlabels>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true[true.spt.between(17,20)]), len(true[true.spt.between(20,30)]), len(true[true.spt.between(30,40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'FP rate {}'.format((ps-truep)/ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict={'classifier': rf,\n",
    "            'sclr':scaler,\n",
    "            'feats':features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the random forest\n",
    "output_file=wisps.OUTPUT_FILES+'/random_forest_classifier.pkl'\n",
    "with open(output_file, 'wb') as file:\n",
    "    pickle.dump(rf_dict,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df=pred_df[(rlabels>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df.to_pickle(wisps.LIBRARIES+'/labelled_by_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slbyids=pd.read_pickle(wisps.OUTPUT_FILES+'/selected_by_indices.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slbyids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sv_df[(sv_df.grism_id.isin(slbyids.grism_id)) & (sv_df.grism_id.isin(cands.grism_id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sv_df[( ~sv_df.grism_id.isin(slbyids.grism_id)) & (sv_df.grism_id.isin(cands.grism_id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slbyids[( ~slbyids.grism_id.isin(sv_df.grism_id)) & (slbyids.grism_id.isin(cands.grism_id))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
